//
// Generated by NVIDIA NVVM Compiler
//
// Compiler Build ID: CL-21458526
// Driver 375.26
// Based on LLVM 3.4svn
//

.version 5.0
.target sm_35, texmode_independent
.address_size 64

	// .globl	kernelone

.entry kernelone(
	.param .u64 .ptr .global .align 4 kernelone_param_0
)
{
	.reg .b32 	%r<8>;
	.reg .b64 	%rd<4>;


	ld.param.u64 	%rd1, [kernelone_param_0];
	mov.b32	%r1, %envreg3;
	mov.u32 	%r2, %ntid.x;
	mov.u32 	%r3, %ctaid.x;
	mad.lo.s32 	%r4, %r3, %r2, %r1;
	mov.u32 	%r5, %tid.x;
	add.s32 	%r6, %r4, %r5;
	mul.wide.u32 	%rd2, %r6, 4;
	add.s64 	%rd3, %rd1, %rd2;
	mov.u32 	%r7, 1065353216;
	st.global.u32 	[%rd3], %r7;
	ret;
}

	// .globl	kernelone_c
.entry kernelone_c(
	.param .u64 .ptr .global .align 8 kernelone_c_param_0
)
{
	.reg .f32 	%f<3>;
	.reg .b32 	%r<7>;
	.reg .b64 	%rd<4>;


	ld.param.u64 	%rd1, [kernelone_c_param_0];
	mov.b32	%r1, %envreg3;
	mov.u32 	%r2, %ntid.x;
	mov.u32 	%r3, %ctaid.x;
	mad.lo.s32 	%r4, %r3, %r2, %r1;
	mov.u32 	%r5, %tid.x;
	add.s32 	%r6, %r4, %r5;
	mul.wide.u32 	%rd2, %r6, 8;
	add.s64 	%rd3, %rd1, %rd2;
	mov.f32 	%f1, 0f00000000;
	mov.f32 	%f2, 0f3F800000;
	st.global.v2.f32 	[%rd3], {%f2, %f1};
	ret;
}

	// .globl	kernelcontract_reswave_10
.entry kernelcontract_reswave_10(
	.param .u64 .ptr .global .align 16 kernelcontract_reswave_10_param_0,
	.param .u64 .ptr .global .align 8 kernelcontract_reswave_10_param_1,
	.param .u64 .ptr .global .align 16 kernelcontract_reswave_10_param_2,
	.param .u64 .ptr .global .align 8 kernelcontract_reswave_10_param_3
)
{
	.reg .f32 	%f<27>;
	.reg .b32 	%r<7>;
	.reg .b64 	%rd<11>;


	ld.param.u64 	%rd1, [kernelcontract_reswave_10_param_0];
	ld.param.u64 	%rd2, [kernelcontract_reswave_10_param_1];
	ld.param.u64 	%rd3, [kernelcontract_reswave_10_param_2];
	ld.param.u64 	%rd4, [kernelcontract_reswave_10_param_3];
	mov.b32	%r1, %envreg3;
	mov.u32 	%r2, %ntid.x;
	mov.u32 	%r3, %ctaid.x;
	mad.lo.s32 	%r4, %r3, %r2, %r1;
	mov.u32 	%r5, %tid.x;
	add.s32 	%r6, %r4, %r5;
	mul.wide.u32 	%rd5, %r6, 16;
	add.s64 	%rd6, %rd1, %rd5;
	ld.global.v4.f32 	{%f1, %f2, %f3, %f4}, [%rd6];
	add.s64 	%rd7, %rd3, %rd5;
	ld.global.v4.f32 	{%f6, %f7, %f8, %f9}, [%rd7];
	mul.f32 	%f13, %f2, %f7;
	fma.rn.f32 	%f14, %f1, %f6, %f13;
	mul.f32 	%f15, %f14, 0f3F000000;
	mul.wide.u32 	%rd8, %r6, 8;
	add.s64 	%rd9, %rd2, %rd8;
	ld.global.v2.f32 	{%f16, %f17}, [%rd9];
	add.s64 	%rd10, %rd4, %rd8;
	ld.global.v2.f32 	{%f19, %f20}, [%rd10];
	mul.f32 	%f21, %f15, %f16;
	st.global.v2.f32 	[%rd10], {%f21, %f20};
	ld.global.v2.f32 	{%f23, %f24}, [%rd9];
	mul.f32 	%f26, %f15, %f24;
	st.global.v2.f32 	[%rd10], {%f21, %f26};
	ret;
}

	// .globl	kernelcontractscalar
.entry kernelcontractscalar(
	.param .u64 .ptr .global .align 4 kernelcontractscalar_param_0,
	.param .u64 .ptr .global .align 4 kernelcontractscalar_param_1,
	.param .u64 .ptr .global .align 8 kernelcontractscalar_param_2,
	.param .u64 .ptr .global .align 8 kernelcontractscalar_param_3,
	.param .u64 .ptr .global .align 8 kernelcontractscalar_param_4
)
{
	.reg .f32 	%f<30>;
	.reg .b32 	%r<7>;
	.reg .b64 	%rd<13>;


	ld.param.u64 	%rd1, [kernelcontractscalar_param_0];
	ld.param.u64 	%rd2, [kernelcontractscalar_param_1];
	ld.param.u64 	%rd3, [kernelcontractscalar_param_2];
	ld.param.u64 	%rd4, [kernelcontractscalar_param_3];
	ld.param.u64 	%rd5, [kernelcontractscalar_param_4];
	mov.b32	%r1, %envreg3;
	mov.u32 	%r2, %ntid.x;
	mov.u32 	%r3, %ctaid.x;
	mad.lo.s32 	%r4, %r3, %r2, %r1;
	mov.u32 	%r5, %tid.x;
	add.s32 	%r6, %r4, %r5;
	mul.wide.u32 	%rd6, %r6, 4;
	add.s64 	%rd7, %rd1, %rd6;
	ld.global.f32 	%f1, [%rd7];
	add.s64 	%rd8, %rd2, %rd6;
	ld.global.f32 	%f2, [%rd8];
	mul.f32 	%f3, %f1, %f2;
	mul.wide.u32 	%rd9, %r6, 8;
	add.s64 	%rd10, %rd3, %rd9;
	ld.global.v2.f32 	{%f4, %f5}, [%rd10];
	add.s64 	%rd11, %rd4, %rd9;
	ld.global.v2.f32 	{%f7, %f8}, [%rd11];
	mul.f32 	%f12, %f5, %f8;
	fma.rn.f32 	%f13, %f4, %f7, %f12;
	add.s64 	%rd12, %rd5, %rd9;
	ld.global.v2.f32 	{%f14, %f15}, [%rd12];
	mul.f32 	%f16, %f3, %f13;
	st.global.v2.f32 	[%rd12], {%f16, %f15};
	ld.global.v2.f32 	{%f18, %f19}, [%rd10];
	neg.f32 	%f21, %f18;
	ld.global.v2.f32 	{%f22, %f23}, [%rd11];
	mul.f32 	%f27, %f19, %f22;
	fma.rn.f32 	%f28, %f21, %f23, %f27;
	mul.f32 	%f29, %f3, %f28;
	st.global.v2.f32 	[%rd12], {%f16, %f29};
	ret;
}

	// .globl	kernelcontractscalar_f_u
.entry kernelcontractscalar_f_u(
	.param .u64 .ptr .global .align 4 kernelcontractscalar_f_u_param_0,
	.param .u64 .ptr .global .align 8 kernelcontractscalar_f_u_param_1,
	.param .u64 .ptr .global .align 8 kernelcontractscalar_f_u_param_2,
	.param .u64 .ptr .global .align 8 kernelcontractscalar_f_u_param_3
)
{
	.reg .f32 	%f<28>;
	.reg .b32 	%r<7>;
	.reg .b64 	%rd<11>;


	ld.param.u64 	%rd1, [kernelcontractscalar_f_u_param_0];
	ld.param.u64 	%rd2, [kernelcontractscalar_f_u_param_1];
	ld.param.u64 	%rd3, [kernelcontractscalar_f_u_param_2];
	ld.param.u64 	%rd4, [kernelcontractscalar_f_u_param_3];
	mov.b32	%r1, %envreg3;
	mov.u32 	%r2, %ntid.x;
	mov.u32 	%r3, %ctaid.x;
	mad.lo.s32 	%r4, %r3, %r2, %r1;
	mov.u32 	%r5, %tid.x;
	add.s32 	%r6, %r4, %r5;
	mul.wide.u32 	%rd5, %r6, 4;
	add.s64 	%rd6, %rd1, %rd5;
	ld.global.f32 	%f1, [%rd6];
	mul.wide.u32 	%rd7, %r6, 8;
	add.s64 	%rd8, %rd2, %rd7;
	ld.global.v2.f32 	{%f2, %f3}, [%rd8];
	add.s64 	%rd9, %rd3, %rd7;
	ld.global.v2.f32 	{%f5, %f6}, [%rd9];
	mul.f32 	%f10, %f3, %f6;
	fma.rn.f32 	%f11, %f2, %f5, %f10;
	add.s64 	%rd10, %rd4, %rd7;
	ld.global.v2.f32 	{%f12, %f13}, [%rd10];
	mul.f32 	%f14, %f1, %f11;
	st.global.v2.f32 	[%rd10], {%f14, %f13};
	ld.global.v2.f32 	{%f16, %f17}, [%rd8];
	neg.f32 	%f19, %f16;
	ld.global.v2.f32 	{%f20, %f21}, [%rd9];
	mul.f32 	%f25, %f17, %f20;
	fma.rn.f32 	%f26, %f19, %f21, %f25;
	mul.f32 	%f27, %f1, %f26;
	st.global.v2.f32 	[%rd10], {%f14, %f27};
	ret;
}

	// .globl	kernelcontractscalar_u_f
.entry kernelcontractscalar_u_f(
	.param .u64 .ptr .global .align 8 kernelcontractscalar_u_f_param_0,
	.param .u64 .ptr .global .align 4 kernelcontractscalar_u_f_param_1,
	.param .u64 .ptr .global .align 8 kernelcontractscalar_u_f_param_2,
	.param .u64 .ptr .global .align 8 kernelcontractscalar_u_f_param_3
)
{
	.reg .f32 	%f<28>;
	.reg .b32 	%r<7>;
	.reg .b64 	%rd<11>;


	ld.param.u64 	%rd1, [kernelcontractscalar_u_f_param_0];
	ld.param.u64 	%rd2, [kernelcontractscalar_u_f_param_1];
	ld.param.u64 	%rd3, [kernelcontractscalar_u_f_param_2];
	ld.param.u64 	%rd4, [kernelcontractscalar_u_f_param_3];
	mov.b32	%r1, %envreg3;
	mov.u32 	%r2, %ntid.x;
	mov.u32 	%r3, %ctaid.x;
	mad.lo.s32 	%r4, %r3, %r2, %r1;
	mov.u32 	%r5, %tid.x;
	add.s32 	%r6, %r4, %r5;
	mul.wide.u32 	%rd5, %r6, 4;
	add.s64 	%rd6, %rd2, %rd5;
	ld.global.f32 	%f1, [%rd6];
	mul.wide.u32 	%rd7, %r6, 8;
	add.s64 	%rd8, %rd1, %rd7;
	ld.global.v2.f32 	{%f2, %f3}, [%rd8];
	add.s64 	%rd9, %rd3, %rd7;
	ld.global.v2.f32 	{%f5, %f6}, [%rd9];
	mul.f32 	%f10, %f3, %f6;
	fma.rn.f32 	%f11, %f2, %f5, %f10;
	add.s64 	%rd10, %rd4, %rd7;
	ld.global.v2.f32 	{%f12, %f13}, [%rd10];
	mul.f32 	%f14, %f1, %f11;
	st.global.v2.f32 	[%rd10], {%f14, %f13};
	ld.global.v2.f32 	{%f16, %f17}, [%rd8];
	neg.f32 	%f19, %f16;
	ld.global.v2.f32 	{%f20, %f21}, [%rd9];
	mul.f32 	%f25, %f17, %f20;
	fma.rn.f32 	%f26, %f19, %f21, %f25;
	mul.f32 	%f27, %f1, %f26;
	st.global.v2.f32 	[%rd10], {%f14, %f27};
	ret;
}

	// .globl	kernelcontractscalar_u_u
.entry kernelcontractscalar_u_u(
	.param .u64 .ptr .global .align 8 kernelcontractscalar_u_u_param_0,
	.param .u64 .ptr .global .align 8 kernelcontractscalar_u_u_param_1,
	.param .u64 .ptr .global .align 8 kernelcontractscalar_u_u_param_2
)
{
	.reg .f32 	%f<25>;
	.reg .b32 	%r<7>;
	.reg .b64 	%rd<8>;


	ld.param.u64 	%rd1, [kernelcontractscalar_u_u_param_0];
	ld.param.u64 	%rd2, [kernelcontractscalar_u_u_param_1];
	ld.param.u64 	%rd3, [kernelcontractscalar_u_u_param_2];
	mov.b32	%r1, %envreg3;
	mov.u32 	%r2, %ntid.x;
	mov.u32 	%r3, %ctaid.x;
	mad.lo.s32 	%r4, %r3, %r2, %r1;
	mov.u32 	%r5, %tid.x;
	add.s32 	%r6, %r4, %r5;
	mul.wide.u32 	%rd4, %r6, 8;
	add.s64 	%rd5, %rd1, %rd4;
	ld.global.v2.f32 	{%f1, %f2}, [%rd5];
	add.s64 	%rd6, %rd2, %rd4;
	ld.global.v2.f32 	{%f4, %f5}, [%rd6];
	mul.f32 	%f9, %f2, %f5;
	add.s64 	%rd7, %rd3, %rd4;
	ld.global.v2.f32 	{%f10, %f11}, [%rd7];
	fma.rn.f32 	%f12, %f1, %f4, %f9;
	st.global.v2.f32 	[%rd7], {%f12, %f11};
	ld.global.v2.f32 	{%f14, %f15}, [%rd5];
	neg.f32 	%f17, %f14;
	ld.global.v2.f32 	{%f18, %f19}, [%rd6];
	mul.f32 	%f23, %f15, %f18;
	fma.rn.f32 	%f24, %f17, %f19, %f23;
	st.global.v2.f32 	[%rd7], {%f12, %f24};
	ret;
}

	// .globl	kernelcontractscalarorbital
.entry kernelcontractscalarorbital(
	.param .u64 .ptr .global .align 4 kernelcontractscalarorbital_param_0,
	.param .u64 .ptr .global .align 4 kernelcontractscalarorbital_param_1,
	.param .u64 .ptr .global .align 4 kernelcontractscalarorbital_param_2
)
{
	.reg .f32 	%f<4>;
	.reg .b32 	%r<7>;
	.reg .b64 	%rd<8>;


	ld.param.u64 	%rd1, [kernelcontractscalarorbital_param_0];
	ld.param.u64 	%rd2, [kernelcontractscalarorbital_param_1];
	ld.param.u64 	%rd3, [kernelcontractscalarorbital_param_2];
	mov.b32	%r1, %envreg3;
	mov.u32 	%r2, %ntid.x;
	mov.u32 	%r3, %ctaid.x;
	mad.lo.s32 	%r4, %r3, %r2, %r1;
	mov.u32 	%r5, %tid.x;
	add.s32 	%r6, %r4, %r5;
	mul.wide.u32 	%rd4, %r6, 4;
	add.s64 	%rd5, %rd1, %rd4;
	ld.global.f32 	%f1, [%rd5];
	add.s64 	%rd6, %rd2, %rd4;
	ld.global.f32 	%f2, [%rd6];
	mul.f32 	%f3, %f1, %f2;
	add.s64 	%rd7, %rd3, %rd4;
	st.global.f32 	[%rd7], %f3;
	ret;
}

	// .globl	kernelcontractmesons
.entry kernelcontractmesons(
	.param .u64 .ptr .global .align 16 kernelcontractmesons_param_0,
	.param .u64 .ptr .global .align 16 kernelcontractmesons_param_1,
	.param .u64 .ptr .global .align 8 kernelcontractmesons_param_2,
	.param .u64 .ptr .global .align 8 kernelcontractmesons_param_3,
	.param .u64 .ptr .global .align 8 kernelcontractmesons_param_4
)
{
	.reg .f32 	%f<42>;
	.reg .b32 	%r<7>;
	.reg .b64 	%rd<13>;


	ld.param.u64 	%rd1, [kernelcontractmesons_param_0];
	ld.param.u64 	%rd2, [kernelcontractmesons_param_1];
	ld.param.u64 	%rd3, [kernelcontractmesons_param_2];
	ld.param.u64 	%rd4, [kernelcontractmesons_param_3];
	ld.param.u64 	%rd5, [kernelcontractmesons_param_4];
	mov.b32	%r1, %envreg3;
	mov.u32 	%r2, %ntid.x;
	mov.u32 	%r3, %ctaid.x;
	mad.lo.s32 	%r4, %r3, %r2, %r1;
	mov.u32 	%r5, %tid.x;
	add.s32 	%r6, %r4, %r5;
	mul.wide.u32 	%rd6, %r6, 16;
	add.s64 	%rd7, %rd1, %rd6;
	ld.global.v4.f32 	{%f1, %f2, %f3, %f4}, [%rd7];
	add.s64 	%rd8, %rd2, %rd6;
	ld.global.v4.f32 	{%f6, %f7, %f8, %f9}, [%rd8];
	mul.f32 	%f13, %f2, %f7;
	fma.rn.f32 	%f14, %f1, %f6, %f13;
	mul.f32 	%f15, %f14, 0f3F000000;
	mul.wide.u32 	%rd9, %r6, 8;
	add.s64 	%rd10, %rd3, %rd9;
	ld.global.v2.f32 	{%f16, %f17}, [%rd10];
	add.s64 	%rd11, %rd4, %rd9;
	ld.global.v2.f32 	{%f19, %f20}, [%rd11];
	mul.f32 	%f24, %f17, %f20;
	fma.rn.f32 	%f25, %f16, %f19, %f24;
	add.s64 	%rd12, %rd5, %rd9;
	ld.global.v2.f32 	{%f26, %f27}, [%rd12];
	mul.f32 	%f28, %f15, %f25;
	st.global.v2.f32 	[%rd12], {%f28, %f27};
	ld.global.v2.f32 	{%f30, %f31}, [%rd10];
	neg.f32 	%f33, %f30;
	ld.global.v2.f32 	{%f34, %f35}, [%rd11];
	mul.f32 	%f39, %f31, %f34;
	fma.rn.f32 	%f40, %f33, %f35, %f39;
	mul.f32 	%f41, %f15, %f40;
	st.global.v2.f32 	[%rd12], {%f28, %f41};
	ret;
}

	// .globl	kernelcontractmesons_v_v
.entry kernelcontractmesons_v_v(
	.param .u64 .ptr .global .align 16 kernelcontractmesons_v_v_param_0,
	.param .u64 .ptr .global .align 16 kernelcontractmesons_v_v_param_1,
	.param .u64 .ptr .global .align 16 kernelcontractmesons_v_v_param_2,
	.param .u64 .ptr .global .align 16 kernelcontractmesons_v_v_param_3,
	.param .u64 .ptr .global .align 8 kernelcontractmesons_v_v_param_4
)
{
	.reg .f32 	%f<39>;
	.reg .b32 	%r<7>;
	.reg .b64 	%rd<13>;


	ld.param.u64 	%rd1, [kernelcontractmesons_v_v_param_0];
	ld.param.u64 	%rd2, [kernelcontractmesons_v_v_param_1];
	ld.param.u64 	%rd3, [kernelcontractmesons_v_v_param_2];
	ld.param.u64 	%rd4, [kernelcontractmesons_v_v_param_3];
	ld.param.u64 	%rd5, [kernelcontractmesons_v_v_param_4];
	mov.b32	%r1, %envreg3;
	mov.u32 	%r2, %ntid.x;
	mov.u32 	%r3, %ctaid.x;
	mad.lo.s32 	%r4, %r3, %r2, %r1;
	mov.u32 	%r5, %tid.x;
	add.s32 	%r6, %r4, %r5;
	mul.wide.u32 	%rd6, %r6, 16;
	add.s64 	%rd7, %rd1, %rd6;
	ld.global.v4.f32 	{%f1, %f2, %f3, %f4}, [%rd7];
	add.s64 	%rd8, %rd3, %rd6;
	ld.global.v4.f32 	{%f7, %f8, %f9, %f10}, [%rd8];
	add.s64 	%rd9, %rd2, %rd6;
	ld.global.v4.f32 	{%f13, %f14, %f15, %f16}, [%rd9];
	add.s64 	%rd10, %rd4, %rd6;
	ld.global.v4.f32 	{%f19, %f20, %f21, %f22}, [%rd10];
	mul.f32 	%f25, %f14, %f20;
	mul.f32 	%f26, %f13, %f19;
	neg.f32 	%f27, %f2;
	neg.f32 	%f28, %f1;
	mul.f32 	%f29, %f14, %f8;
	mul.f32 	%f30, %f13, %f7;
	fma.rn.f32 	%f31, %f1, %f7, %f26;
	fma.rn.f32 	%f32, %f2, %f8, %f25;
	add.f32 	%f33, %f31, %f32;
	mul.wide.u32 	%rd11, %r6, 8;
	add.s64 	%rd12, %rd5, %rd11;
	fma.rn.f32 	%f34, %f28, %f19, %f30;
	fma.rn.f32 	%f35, %f27, %f20, %f29;
	add.f32 	%f36, %f34, %f35;
	mul.f32 	%f37, %f36, 0f3F000000;
	mul.f32 	%f38, %f33, 0f3F000000;
	st.global.v2.f32 	[%rd12], {%f38, %f37};
	ret;
}

	// .globl	kernelcontractmesons_v_vs
.entry kernelcontractmesons_v_vs(
	.param .u64 .ptr .global .align 16 kernelcontractmesons_v_vs_param_0,
	.param .u64 .ptr .global .align 16 kernelcontractmesons_v_vs_param_1,
	.param .u64 .ptr .global .align 16 kernelcontractmesons_v_vs_param_2,
	.param .u64 .ptr .global .align 16 kernelcontractmesons_v_vs_param_3,
	.param .u64 .ptr .global .align 8 kernelcontractmesons_v_vs_param_4,
	.param .u64 .ptr .global .align 8 kernelcontractmesons_v_vs_param_5
)
{
	.reg .f32 	%f<57>;
	.reg .b32 	%r<7>;
	.reg .b64 	%rd<15>;


	ld.param.u64 	%rd1, [kernelcontractmesons_v_vs_param_0];
	ld.param.u64 	%rd2, [kernelcontractmesons_v_vs_param_1];
	ld.param.u64 	%rd3, [kernelcontractmesons_v_vs_param_2];
	ld.param.u64 	%rd4, [kernelcontractmesons_v_vs_param_3];
	ld.param.u64 	%rd5, [kernelcontractmesons_v_vs_param_4];
	ld.param.u64 	%rd6, [kernelcontractmesons_v_vs_param_5];
	mov.b32	%r1, %envreg3;
	mov.u32 	%r2, %ntid.x;
	mov.u32 	%r3, %ctaid.x;
	mad.lo.s32 	%r4, %r3, %r2, %r1;
	mov.u32 	%r5, %tid.x;
	add.s32 	%r6, %r4, %r5;
	mul.wide.u32 	%rd7, %r6, 16;
	add.s64 	%rd8, %rd1, %rd7;
	ld.global.v4.f32 	{%f1, %f2, %f3, %f4}, [%rd8];
	add.s64 	%rd9, %rd3, %rd7;
	ld.global.v4.f32 	{%f7, %f8, %f9, %f10}, [%rd9];
	add.s64 	%rd10, %rd2, %rd7;
	ld.global.v4.f32 	{%f13, %f14, %f15, %f16}, [%rd10];
	add.s64 	%rd11, %rd4, %rd7;
	ld.global.v4.f32 	{%f19, %f20, %f21, %f22}, [%rd11];
	mul.f32 	%f25, %f14, %f20;
	mul.f32 	%f26, %f13, %f19;
	neg.f32 	%f27, %f2;
	neg.f32 	%f28, %f1;
	mul.f32 	%f29, %f14, %f8;
	mul.f32 	%f30, %f13, %f7;
	mul.wide.u32 	%rd12, %r6, 8;
	add.s64 	%rd13, %rd5, %rd12;
	ld.global.v2.f32 	{%f31, %f32}, [%rd13];
	mul.f32 	%f34, %f31, 0f3F000000;
	fma.rn.f32 	%f35, %f1, %f7, %f26;
	fma.rn.f32 	%f36, %f2, %f8, %f25;
	add.f32 	%f37, %f35, %f36;
	mul.f32 	%f39, %f32, 0f3F000000;
	fma.rn.f32 	%f40, %f28, %f19, %f30;
	fma.rn.f32 	%f41, %f27, %f20, %f29;
	add.f32 	%f42, %f40, %f41;
	mul.f32 	%f43, %f42, %f39;
	neg.f32 	%f44, %f43;
	add.s64 	%rd14, %rd6, %rd12;
	ld.global.v2.f32 	{%f45, %f46}, [%rd14];
	fma.rn.f32 	%f47, %f34, %f37, %f44;
	st.global.v2.f32 	[%rd14], {%f47, %f46};
	ld.global.v2.f32 	{%f49, %f50}, [%rd13];
	mul.f32 	%f52, %f49, 0f3F000000;
	mul.f32 	%f54, %f50, 0f3F000000;
	mul.f32 	%f55, %f37, %f54;
	fma.rn.f32 	%f56, %f52, %f42, %f55;
	st.global.v2.f32 	[%rd14], {%f47, %f56};
	ret;
}

	// .globl	kernelcontractmesons_s_v
.entry kernelcontractmesons_s_v(
	.param .u64 .ptr .global .align 16 kernelcontractmesons_s_v_param_0,
	.param .u64 .ptr .global .align 8 kernelcontractmesons_s_v_param_1,
	.param .u64 .ptr .global .align 16 kernelcontractmesons_s_v_param_2,
	.param .u64 .ptr .global .align 16 kernelcontractmesons_s_v_param_3,
	.param .u64 .ptr .global .align 8 kernelcontractmesons_s_v_param_4
)
{
	.reg .f32 	%f<41>;
	.reg .b32 	%r<7>;
	.reg .b64 	%rd<13>;


	ld.param.u64 	%rd1, [kernelcontractmesons_s_v_param_0];
	ld.param.u64 	%rd2, [kernelcontractmesons_s_v_param_1];
	ld.param.u64 	%rd3, [kernelcontractmesons_s_v_param_2];
	ld.param.u64 	%rd4, [kernelcontractmesons_s_v_param_3];
	ld.param.u64 	%rd5, [kernelcontractmesons_s_v_param_4];
	mov.b32	%r1, %envreg3;
	mov.u32 	%r2, %ntid.x;
	mov.u32 	%r3, %ctaid.x;
	mad.lo.s32 	%r4, %r3, %r2, %r1;
	mov.u32 	%r5, %tid.x;
	add.s32 	%r6, %r4, %r5;
	mul.wide.u32 	%rd6, %r6, 16;
	add.s64 	%rd7, %rd1, %rd6;
	ld.global.v4.f32 	{%f1, %f2, %f3, %f4}, [%rd7];
	mul.wide.u32 	%rd8, %r6, 8;
	add.s64 	%rd9, %rd2, %rd8;
	ld.global.v2.f32 	{%f7, %f8}, [%rd9];
	mul.f32 	%f11, %f1, %f7;
	mul.f32 	%f12, %f2, %f7;
	mul.f32 	%f13, %f1, %f8;
	mul.f32 	%f14, %f2, %f8;
	add.s64 	%rd10, %rd3, %rd6;
	ld.global.v4.f32 	{%f15, %f16, %f17, %f18}, [%rd10];
	add.s64 	%rd11, %rd4, %rd6;
	ld.global.v4.f32 	{%f21, %f22, %f23, %f24}, [%rd11];
	mul.f32 	%f27, %f22, %f14;
	mul.f32 	%f28, %f21, %f13;
	neg.f32 	%f29, %f12;
	neg.f32 	%f30, %f11;
	mul.f32 	%f31, %f16, %f14;
	mul.f32 	%f32, %f15, %f13;
	fma.rn.f32 	%f33, %f11, %f15, %f28;
	fma.rn.f32 	%f34, %f12, %f16, %f27;
	add.f32 	%f35, %f33, %f34;
	add.s64 	%rd12, %rd5, %rd8;
	fma.rn.f32 	%f36, %f30, %f21, %f32;
	fma.rn.f32 	%f37, %f29, %f22, %f31;
	add.f32 	%f38, %f36, %f37;
	mul.f32 	%f39, %f38, 0f3F000000;
	mul.f32 	%f40, %f35, 0f3F000000;
	st.global.v2.f32 	[%rd12], {%f40, %f39};
	ret;
}

	// .globl	kernelcontractmesons_v_s
.entry kernelcontractmesons_v_s(
	.param .u64 .ptr .global .align 16 kernelcontractmesons_v_s_param_0,
	.param .u64 .ptr .global .align 16 kernelcontractmesons_v_s_param_1,
	.param .u64 .ptr .global .align 16 kernelcontractmesons_v_s_param_2,
	.param .u64 .ptr .global .align 8 kernelcontractmesons_v_s_param_3,
	.param .u64 .ptr .global .align 8 kernelcontractmesons_v_s_param_4
)
{
	.reg .f32 	%f<41>;
	.reg .b32 	%r<7>;
	.reg .b64 	%rd<13>;


	ld.param.u64 	%rd1, [kernelcontractmesons_v_s_param_0];
	ld.param.u64 	%rd2, [kernelcontractmesons_v_s_param_1];
	ld.param.u64 	%rd3, [kernelcontractmesons_v_s_param_2];
	ld.param.u64 	%rd4, [kernelcontractmesons_v_s_param_3];
	ld.param.u64 	%rd5, [kernelcontractmesons_v_s_param_4];
	mov.b32	%r1, %envreg3;
	mov.u32 	%r2, %ntid.x;
	mov.u32 	%r3, %ctaid.x;
	mad.lo.s32 	%r4, %r3, %r2, %r1;
	mov.u32 	%r5, %tid.x;
	add.s32 	%r6, %r4, %r5;
	mul.wide.u32 	%rd6, %r6, 16;
	add.s64 	%rd7, %rd1, %rd6;
	ld.global.v4.f32 	{%f1, %f2, %f3, %f4}, [%rd7];
	mul.wide.u32 	%rd8, %r6, 8;
	add.s64 	%rd9, %rd4, %rd8;
	ld.global.v2.f32 	{%f7, %f8}, [%rd9];
	mul.f32 	%f11, %f1, %f7;
	mul.f32 	%f12, %f2, %f7;
	mul.f32 	%f13, %f1, %f8;
	mul.f32 	%f14, %f2, %f8;
	add.s64 	%rd10, %rd2, %rd6;
	ld.global.v4.f32 	{%f15, %f16, %f17, %f18}, [%rd10];
	add.s64 	%rd11, %rd3, %rd6;
	ld.global.v4.f32 	{%f21, %f22, %f23, %f24}, [%rd11];
	mul.f32 	%f27, %f22, %f14;
	mul.f32 	%f28, %f21, %f13;
	neg.f32 	%f29, %f16;
	neg.f32 	%f30, %f15;
	mul.f32 	%f31, %f22, %f12;
	mul.f32 	%f32, %f21, %f11;
	fma.rn.f32 	%f33, %f15, %f11, %f28;
	fma.rn.f32 	%f34, %f16, %f12, %f27;
	add.f32 	%f35, %f33, %f34;
	add.s64 	%rd12, %rd5, %rd8;
	fma.rn.f32 	%f36, %f30, %f13, %f32;
	fma.rn.f32 	%f37, %f29, %f14, %f31;
	add.f32 	%f38, %f36, %f37;
	mul.f32 	%f39, %f38, 0f3F000000;
	mul.f32 	%f40, %f35, 0f3F000000;
	st.global.v2.f32 	[%rd12], {%f40, %f39};
	ret;
}

	// .globl	kernelcontractmesonsorbital
.entry kernelcontractmesonsorbital(
	.param .u64 .ptr .global .align 16 kernelcontractmesonsorbital_param_0,
	.param .u64 .ptr .global .align 16 kernelcontractmesonsorbital_param_1,
	.param .u64 .ptr .global .align 4 kernelcontractmesonsorbital_param_2
)
{
	.reg .f32 	%f<16>;
	.reg .b32 	%r<7>;
	.reg .b64 	%rd<9>;


	ld.param.u64 	%rd1, [kernelcontractmesonsorbital_param_0];
	ld.param.u64 	%rd2, [kernelcontractmesonsorbital_param_1];
	ld.param.u64 	%rd3, [kernelcontractmesonsorbital_param_2];
	mov.b32	%r1, %envreg3;
	mov.u32 	%r2, %ntid.x;
	mov.u32 	%r3, %ctaid.x;
	mad.lo.s32 	%r4, %r3, %r2, %r1;
	mov.u32 	%r5, %tid.x;
	add.s32 	%r6, %r4, %r5;
	mul.wide.u32 	%rd4, %r6, 16;
	add.s64 	%rd5, %rd1, %rd4;
	ld.global.v4.f32 	{%f1, %f2, %f3, %f4}, [%rd5];
	add.s64 	%rd6, %rd2, %rd4;
	ld.global.v4.f32 	{%f6, %f7, %f8, %f9}, [%rd6];
	mul.f32 	%f13, %f2, %f7;
	fma.rn.f32 	%f14, %f1, %f6, %f13;
	mul.f32 	%f15, %f14, 0f3F000000;
	mul.wide.u32 	%rd7, %r6, 4;
	add.s64 	%rd8, %rd3, %rd7;
	st.global.f32 	[%rd8], %f15;
	ret;
}

	// .globl	kernelcontractradmesons
.entry kernelcontractradmesons(
	.param .u64 .ptr .global .align 16 kernelcontractradmesons_param_0,
	.param .u64 .ptr .global .align 16 kernelcontractradmesons_param_1,
	.param .u64 .ptr .global .align 16 kernelcontractradmesons_param_2,
	.param .u64 .ptr .global .align 8 kernelcontractradmesons_param_3,
	.param .u64 .ptr .global .align 8 kernelcontractradmesons_param_4,
	.param .u64 .ptr .global .align 8 kernelcontractradmesons_param_5
)
{
	.reg .f32 	%f<102>;
	.reg .b32 	%r<7>;
	.reg .b64 	%rd<15>;


	ld.param.u64 	%rd1, [kernelcontractradmesons_param_0];
	ld.param.u64 	%rd2, [kernelcontractradmesons_param_1];
	ld.param.u64 	%rd3, [kernelcontractradmesons_param_2];
	ld.param.u64 	%rd4, [kernelcontractradmesons_param_3];
	ld.param.u64 	%rd5, [kernelcontractradmesons_param_4];
	ld.param.u64 	%rd6, [kernelcontractradmesons_param_5];
	mov.b32	%r1, %envreg3;
	mov.u32 	%r2, %ntid.x;
	mov.u32 	%r3, %ctaid.x;
	mad.lo.s32 	%r4, %r3, %r2, %r1;
	mov.u32 	%r5, %tid.x;
	add.s32 	%r6, %r4, %r5;
	mul.wide.u32 	%rd7, %r6, 64;
	add.s64 	%rd8, %rd1, %rd7;
	ld.global.v4.f32 	{%f1, %f2, %f3, %f4}, [%rd8];
	add.s64 	%rd9, %rd3, %rd7;
	ld.global.v4.f32 	{%f6, %f7, %f8, %f9}, [%rd9];
	ld.global.v4.f32 	{%f12, %f13, %f14, %f15}, [%rd9+16];
	mul.f32 	%f17, %f2, %f12;
	fma.rn.f32 	%f18, %f1, %f6, %f17;
	ld.global.v4.f32 	{%f20, %f21, %f22, %f23}, [%rd9+32];
	fma.rn.f32 	%f25, %f3, %f20, %f18;
	ld.global.v4.f32 	{%f26, %f27, %f28, %f29}, [%rd8+16];
	mul.f32 	%f32, %f27, %f12;
	fma.rn.f32 	%f33, %f26, %f6, %f32;
	fma.rn.f32 	%f35, %f28, %f20, %f33;
	mul.f32 	%f38, %f2, %f13;
	fma.rn.f32 	%f39, %f1, %f7, %f38;
	fma.rn.f32 	%f41, %f3, %f21, %f39;
	mul.f32 	%f42, %f27, %f13;
	fma.rn.f32 	%f43, %f26, %f7, %f42;
	fma.rn.f32 	%f44, %f28, %f21, %f43;
	mul.f32 	%f47, %f2, %f14;
	fma.rn.f32 	%f48, %f1, %f8, %f47;
	fma.rn.f32 	%f50, %f3, %f22, %f48;
	mul.f32 	%f51, %f27, %f14;
	fma.rn.f32 	%f52, %f26, %f8, %f51;
	fma.rn.f32 	%f53, %f28, %f22, %f52;
	add.s64 	%rd10, %rd2, %rd7;
	ld.global.v4.f32 	{%f54, %f55, %f56, %f57}, [%rd10];
	mul.f32 	%f60, %f41, %f55;
	fma.rn.f32 	%f61, %f25, %f54, %f60;
	fma.rn.f32 	%f63, %f50, %f56, %f61;
	ld.global.v4.f32 	{%f64, %f65, %f66, %f67}, [%rd10+16];
	mul.f32 	%f70, %f44, %f65;
	fma.rn.f32 	%f71, %f35, %f64, %f70;
	fma.rn.f32 	%f73, %f53, %f66, %f71;
	add.f32 	%f74, %f63, %f73;
	mul.f32 	%f75, %f74, 0fBF000000;
	mul.wide.u32 	%rd11, %r6, 8;
	add.s64 	%rd12, %rd4, %rd11;
	ld.global.v2.f32 	{%f76, %f77}, [%rd12];
	add.s64 	%rd13, %rd5, %rd11;
	ld.global.v2.f32 	{%f79, %f80}, [%rd13];
	mul.f32 	%f84, %f77, %f80;
	fma.rn.f32 	%f85, %f76, %f79, %f84;
	add.s64 	%rd14, %rd6, %rd11;
	ld.global.v2.f32 	{%f86, %f87}, [%rd14];
	mul.f32 	%f88, %f75, %f85;
	st.global.v2.f32 	[%rd14], {%f88, %f87};
	ld.global.v2.f32 	{%f90, %f91}, [%rd12];
	neg.f32 	%f93, %f90;
	ld.global.v2.f32 	{%f94, %f95}, [%rd13];
	mul.f32 	%f99, %f91, %f94;
	fma.rn.f32 	%f100, %f93, %f95, %f99;
	mul.f32 	%f101, %f75, %f100;
	st.global.v2.f32 	[%rd14], {%f88, %f101};
	ret;
}

	// .globl	kernelcontractradmesonsorbital
.entry kernelcontractradmesonsorbital(
	.param .u64 .ptr .global .align 16 kernelcontractradmesonsorbital_param_0,
	.param .u64 .ptr .global .align 16 kernelcontractradmesonsorbital_param_1,
	.param .u64 .ptr .global .align 16 kernelcontractradmesonsorbital_param_2,
	.param .u64 .ptr .global .align 4 kernelcontractradmesonsorbital_param_3
)
{
	.reg .f32 	%f<76>;
	.reg .b32 	%r<7>;
	.reg .b64 	%rd<11>;


	ld.param.u64 	%rd1, [kernelcontractradmesonsorbital_param_0];
	ld.param.u64 	%rd2, [kernelcontractradmesonsorbital_param_1];
	ld.param.u64 	%rd3, [kernelcontractradmesonsorbital_param_2];
	ld.param.u64 	%rd4, [kernelcontractradmesonsorbital_param_3];
	mov.b32	%r1, %envreg3;
	mov.u32 	%r2, %ntid.x;
	mov.u32 	%r3, %ctaid.x;
	mad.lo.s32 	%r4, %r3, %r2, %r1;
	mov.u32 	%r5, %tid.x;
	add.s32 	%r6, %r4, %r5;
	mul.wide.u32 	%rd5, %r6, 64;
	add.s64 	%rd6, %rd1, %rd5;
	ld.global.v4.f32 	{%f1, %f2, %f3, %f4}, [%rd6];
	add.s64 	%rd7, %rd3, %rd5;
	ld.global.v4.f32 	{%f6, %f7, %f8, %f9}, [%rd7];
	ld.global.v4.f32 	{%f12, %f13, %f14, %f15}, [%rd7+16];
	mul.f32 	%f17, %f2, %f12;
	fma.rn.f32 	%f18, %f1, %f6, %f17;
	ld.global.v4.f32 	{%f20, %f21, %f22, %f23}, [%rd7+32];
	fma.rn.f32 	%f25, %f3, %f20, %f18;
	ld.global.v4.f32 	{%f26, %f27, %f28, %f29}, [%rd6+16];
	mul.f32 	%f32, %f27, %f12;
	fma.rn.f32 	%f33, %f26, %f6, %f32;
	fma.rn.f32 	%f35, %f28, %f20, %f33;
	mul.f32 	%f38, %f2, %f13;
	fma.rn.f32 	%f39, %f1, %f7, %f38;
	fma.rn.f32 	%f41, %f3, %f21, %f39;
	mul.f32 	%f42, %f27, %f13;
	fma.rn.f32 	%f43, %f26, %f7, %f42;
	fma.rn.f32 	%f44, %f28, %f21, %f43;
	mul.f32 	%f47, %f2, %f14;
	fma.rn.f32 	%f48, %f1, %f8, %f47;
	fma.rn.f32 	%f50, %f3, %f22, %f48;
	mul.f32 	%f51, %f27, %f14;
	fma.rn.f32 	%f52, %f26, %f8, %f51;
	fma.rn.f32 	%f53, %f28, %f22, %f52;
	add.s64 	%rd8, %rd2, %rd5;
	ld.global.v4.f32 	{%f54, %f55, %f56, %f57}, [%rd8];
	mul.f32 	%f60, %f41, %f55;
	fma.rn.f32 	%f61, %f25, %f54, %f60;
	fma.rn.f32 	%f63, %f50, %f56, %f61;
	ld.global.v4.f32 	{%f64, %f65, %f66, %f67}, [%rd8+16];
	mul.f32 	%f70, %f44, %f65;
	fma.rn.f32 	%f71, %f35, %f64, %f70;
	fma.rn.f32 	%f73, %f53, %f66, %f71;
	add.f32 	%f74, %f63, %f73;
	mul.f32 	%f75, %f74, 0fBF000000;
	mul.wide.u32 	%rd9, %r6, 4;
	add.s64 	%rd10, %rd4, %rd9;
	st.global.f32 	[%rd10], %f75;
	ret;
}

	// .globl	kernelcontractradmesons_f_u
.entry kernelcontractradmesons_f_u(
	.param .u64 .ptr .global .align 16 kernelcontractradmesons_f_u_param_0,
	.param .u64 .ptr .global .align 8 kernelcontractradmesons_f_u_param_1,
	.param .u64 .ptr .global .align 16 kernelcontractradmesons_f_u_param_2,
	.param .u64 .ptr .global .align 16 kernelcontractradmesons_f_u_param_3,
	.param .u64 .ptr .global .align 16 kernelcontractradmesons_f_u_param_4,
	.param .u64 .ptr .global .align 8 kernelcontractradmesons_f_u_param_5
)
{
	.reg .f32 	%f<154>;
	.reg .b32 	%r<7>;
	.reg .b64 	%rd<15>;


	ld.param.u64 	%rd1, [kernelcontractradmesons_f_u_param_0];
	ld.param.u64 	%rd2, [kernelcontractradmesons_f_u_param_1];
	ld.param.u64 	%rd3, [kernelcontractradmesons_f_u_param_2];
	ld.param.u64 	%rd4, [kernelcontractradmesons_f_u_param_3];
	ld.param.u64 	%rd5, [kernelcontractradmesons_f_u_param_4];
	ld.param.u64 	%rd6, [kernelcontractradmesons_f_u_param_5];
	mov.b32	%r1, %envreg3;
	mov.u32 	%r2, %ntid.x;
	mov.u32 	%r3, %ctaid.x;
	mad.lo.s32 	%r4, %r3, %r2, %r1;
	mov.u32 	%r5, %tid.x;
	add.s32 	%r6, %r4, %r5;
	mul.wide.u32 	%rd7, %r6, 64;
	add.s64 	%rd8, %rd1, %rd7;
	ld.global.v4.f32 	{%f1, %f2, %f3, %f4}, [%rd8];
	mul.wide.u32 	%rd9, %r6, 8;
	add.s64 	%rd10, %rd2, %rd9;
	ld.global.v2.f32 	{%f8, %f9}, [%rd10];
	ld.global.v4.f32 	{%f12, %f13, %f14, %f15}, [%rd8+16];
	mul.f32 	%f19, %f1, %f8;
	add.s64 	%rd11, %rd3, %rd7;
	ld.global.v4.f32 	{%f20, %f21, %f22, %f23}, [%rd11];
	mul.f32 	%f25, %f2, %f8;
	ld.global.v4.f32 	{%f26, %f27, %f28, %f29}, [%rd11+16];
	mul.f32 	%f31, %f25, %f26;
	fma.rn.f32 	%f32, %f19, %f20, %f31;
	mul.f32 	%f33, %f3, %f8;
	ld.global.v4.f32 	{%f34, %f35, %f36, %f37}, [%rd11+32];
	fma.rn.f32 	%f39, %f33, %f34, %f32;
	mul.f32 	%f40, %f12, %f8;
	mul.f32 	%f41, %f13, %f8;
	mul.f32 	%f42, %f41, %f26;
	fma.rn.f32 	%f43, %f40, %f20, %f42;
	mul.f32 	%f44, %f14, %f8;
	fma.rn.f32 	%f45, %f44, %f34, %f43;
	mul.f32 	%f48, %f25, %f27;
	fma.rn.f32 	%f49, %f19, %f21, %f48;
	fma.rn.f32 	%f51, %f33, %f35, %f49;
	mul.f32 	%f52, %f41, %f27;
	fma.rn.f32 	%f53, %f40, %f21, %f52;
	fma.rn.f32 	%f54, %f44, %f35, %f53;
	mul.f32 	%f57, %f25, %f28;
	fma.rn.f32 	%f58, %f19, %f22, %f57;
	fma.rn.f32 	%f60, %f33, %f36, %f58;
	mul.f32 	%f61, %f41, %f28;
	fma.rn.f32 	%f62, %f40, %f22, %f61;
	fma.rn.f32 	%f63, %f44, %f36, %f62;
	mul.f32 	%f64, %f1, %f9;
	mul.f32 	%f65, %f2, %f9;
	mul.f32 	%f66, %f65, %f26;
	fma.rn.f32 	%f67, %f64, %f20, %f66;
	mul.f32 	%f68, %f3, %f9;
	fma.rn.f32 	%f69, %f68, %f34, %f67;
	mul.f32 	%f70, %f12, %f9;
	mul.f32 	%f71, %f13, %f9;
	mul.f32 	%f72, %f71, %f26;
	fma.rn.f32 	%f73, %f70, %f20, %f72;
	mul.f32 	%f74, %f14, %f9;
	fma.rn.f32 	%f75, %f74, %f34, %f73;
	mul.f32 	%f76, %f65, %f27;
	fma.rn.f32 	%f77, %f64, %f21, %f76;
	fma.rn.f32 	%f78, %f68, %f35, %f77;
	mul.f32 	%f79, %f71, %f27;
	fma.rn.f32 	%f80, %f70, %f21, %f79;
	fma.rn.f32 	%f81, %f74, %f35, %f80;
	mul.f32 	%f82, %f65, %f28;
	fma.rn.f32 	%f83, %f64, %f22, %f82;
	fma.rn.f32 	%f84, %f68, %f36, %f83;
	mul.f32 	%f85, %f71, %f28;
	fma.rn.f32 	%f86, %f70, %f22, %f85;
	fma.rn.f32 	%f87, %f74, %f36, %f86;
	add.s64 	%rd12, %rd4, %rd7;
	ld.global.v4.f32 	{%f88, %f89, %f90, %f91}, [%rd12];
	mul.f32 	%f94, %f51, %f89;
	fma.rn.f32 	%f95, %f39, %f88, %f94;
	fma.rn.f32 	%f97, %f60, %f90, %f95;
	add.s64 	%rd13, %rd5, %rd7;
	ld.global.v4.f32 	{%f98, %f99, %f100, %f101}, [%rd13];
	mul.f32 	%f104, %f78, %f99;
	fma.rn.f32 	%f105, %f69, %f98, %f104;
	fma.rn.f32 	%f107, %f84, %f100, %f105;
	ld.global.v4.f32 	{%f108, %f109, %f110, %f111}, [%rd12+16];
	mul.f32 	%f114, %f54, %f109;
	fma.rn.f32 	%f115, %f45, %f108, %f114;
	fma.rn.f32 	%f117, %f63, %f110, %f115;
	ld.global.v4.f32 	{%f118, %f119, %f120, %f121}, [%rd13+16];
	mul.f32 	%f124, %f81, %f119;
	fma.rn.f32 	%f125, %f75, %f118, %f124;
	fma.rn.f32 	%f127, %f87, %f120, %f125;
	neg.f32 	%f128, %f39;
	mul.f32 	%f129, %f51, %f99;
	neg.f32 	%f130, %f129;
	fma.rn.f32 	%f131, %f128, %f98, %f130;
	neg.f32 	%f132, %f60;
	fma.rn.f32 	%f133, %f132, %f100, %f131;
	mul.f32 	%f134, %f78, %f89;
	fma.rn.f32 	%f135, %f69, %f88, %f134;
	fma.rn.f32 	%f136, %f84, %f90, %f135;
	neg.f32 	%f137, %f45;
	mul.f32 	%f138, %f54, %f119;
	neg.f32 	%f139, %f138;
	fma.rn.f32 	%f140, %f137, %f118, %f139;
	neg.f32 	%f141, %f63;
	fma.rn.f32 	%f142, %f141, %f120, %f140;
	mul.f32 	%f143, %f81, %f109;
	fma.rn.f32 	%f144, %f75, %f108, %f143;
	fma.rn.f32 	%f145, %f87, %f110, %f144;
	add.f32 	%f146, %f97, %f107;
	add.f32 	%f147, %f146, %f117;
	add.f32 	%f148, %f147, %f127;
	add.s64 	%rd14, %rd6, %rd9;
	add.f32 	%f149, %f133, %f136;
	add.f32 	%f150, %f149, %f142;
	add.f32 	%f151, %f150, %f145;
	mul.f32 	%f152, %f148, 0fBF000000;
	mul.f32 	%f153, %f151, 0fBF000000;
	st.global.v2.f32 	[%rd14], {%f152, %f153};
	ret;
}

	// .globl	kernelcontractradmesons_u_f
.entry kernelcontractradmesons_u_f(
	.param .u64 .ptr .global .align 16 kernelcontractradmesons_u_f_param_0,
	.param .u64 .ptr .global .align 16 kernelcontractradmesons_u_f_param_1,
	.param .u64 .ptr .global .align 16 kernelcontractradmesons_u_f_param_2,
	.param .u64 .ptr .global .align 16 kernelcontractradmesons_u_f_param_3,
	.param .u64 .ptr .global .align 8 kernelcontractradmesons_u_f_param_4,
	.param .u64 .ptr .global .align 8 kernelcontractradmesons_u_f_param_5
)
{
	.reg .f32 	%f<154>;
	.reg .b32 	%r<7>;
	.reg .b64 	%rd<15>;


	ld.param.u64 	%rd1, [kernelcontractradmesons_u_f_param_0];
	ld.param.u64 	%rd2, [kernelcontractradmesons_u_f_param_1];
	ld.param.u64 	%rd3, [kernelcontractradmesons_u_f_param_2];
	ld.param.u64 	%rd4, [kernelcontractradmesons_u_f_param_3];
	ld.param.u64 	%rd5, [kernelcontractradmesons_u_f_param_4];
	ld.param.u64 	%rd6, [kernelcontractradmesons_u_f_param_5];
	mov.b32	%r1, %envreg3;
	mov.u32 	%r2, %ntid.x;
	mov.u32 	%r3, %ctaid.x;
	mad.lo.s32 	%r4, %r3, %r2, %r1;
	mov.u32 	%r5, %tid.x;
	add.s32 	%r6, %r4, %r5;
	mul.wide.u32 	%rd7, %r6, 64;
	add.s64 	%rd8, %rd4, %rd7;
	ld.global.v4.f32 	{%f1, %f2, %f3, %f4}, [%rd8];
	mul.wide.u32 	%rd9, %r6, 8;
	add.s64 	%rd10, %rd5, %rd9;
	ld.global.v2.f32 	{%f8, %f9}, [%rd10];
	ld.global.v4.f32 	{%f12, %f13, %f14, %f15}, [%rd8+16];
	add.s64 	%rd11, %rd1, %rd7;
	ld.global.v4.f32 	{%f19, %f20, %f21, %f22}, [%rd11];
	add.s64 	%rd12, %rd3, %rd7;
	ld.global.v4.f32 	{%f24, %f25, %f26, %f27}, [%rd12];
	ld.global.v4.f32 	{%f30, %f31, %f32, %f33}, [%rd12+16];
	mul.f32 	%f35, %f20, %f30;
	fma.rn.f32 	%f36, %f19, %f24, %f35;
	ld.global.v4.f32 	{%f38, %f39, %f40, %f41}, [%rd12+32];
	fma.rn.f32 	%f43, %f21, %f38, %f36;
	ld.global.v4.f32 	{%f44, %f45, %f46, %f47}, [%rd11+16];
	mul.f32 	%f50, %f45, %f30;
	fma.rn.f32 	%f51, %f44, %f24, %f50;
	fma.rn.f32 	%f53, %f46, %f38, %f51;
	mul.f32 	%f56, %f20, %f31;
	fma.rn.f32 	%f57, %f19, %f25, %f56;
	fma.rn.f32 	%f59, %f21, %f39, %f57;
	mul.f32 	%f60, %f45, %f31;
	fma.rn.f32 	%f61, %f44, %f25, %f60;
	fma.rn.f32 	%f62, %f46, %f39, %f61;
	mul.f32 	%f65, %f20, %f32;
	fma.rn.f32 	%f66, %f19, %f26, %f65;
	fma.rn.f32 	%f68, %f21, %f40, %f66;
	mul.f32 	%f69, %f45, %f32;
	fma.rn.f32 	%f70, %f44, %f26, %f69;
	fma.rn.f32 	%f71, %f46, %f40, %f70;
	add.s64 	%rd13, %rd2, %rd7;
	ld.global.v4.f32 	{%f72, %f73, %f74, %f75}, [%rd13];
	mul.f32 	%f78, %f73, %f30;
	fma.rn.f32 	%f79, %f72, %f24, %f78;
	fma.rn.f32 	%f81, %f74, %f38, %f79;
	ld.global.v4.f32 	{%f82, %f83, %f84, %f85}, [%rd13+16];
	mul.f32 	%f88, %f83, %f30;
	fma.rn.f32 	%f89, %f82, %f24, %f88;
	fma.rn.f32 	%f91, %f84, %f38, %f89;
	mul.f32 	%f92, %f73, %f31;
	fma.rn.f32 	%f93, %f72, %f25, %f92;
	fma.rn.f32 	%f94, %f74, %f39, %f93;
	mul.f32 	%f95, %f83, %f31;
	fma.rn.f32 	%f96, %f82, %f25, %f95;
	fma.rn.f32 	%f97, %f84, %f39, %f96;
	mul.f32 	%f98, %f73, %f32;
	fma.rn.f32 	%f99, %f72, %f26, %f98;
	fma.rn.f32 	%f100, %f74, %f40, %f99;
	mul.f32 	%f101, %f83, %f32;
	fma.rn.f32 	%f102, %f82, %f26, %f101;
	fma.rn.f32 	%f103, %f84, %f40, %f102;
	mul.f32 	%f104, %f1, %f8;
	mul.f32 	%f105, %f2, %f8;
	mul.f32 	%f106, %f105, %f59;
	fma.rn.f32 	%f107, %f43, %f104, %f106;
	mul.f32 	%f108, %f3, %f8;
	fma.rn.f32 	%f109, %f68, %f108, %f107;
	mul.f32 	%f110, %f1, %f9;
	mul.f32 	%f111, %f2, %f9;
	mul.f32 	%f112, %f111, %f94;
	fma.rn.f32 	%f113, %f81, %f110, %f112;
	mul.f32 	%f114, %f3, %f9;
	fma.rn.f32 	%f115, %f100, %f114, %f113;
	mul.f32 	%f116, %f12, %f8;
	mul.f32 	%f117, %f13, %f8;
	mul.f32 	%f118, %f117, %f62;
	fma.rn.f32 	%f119, %f53, %f116, %f118;
	mul.f32 	%f120, %f14, %f8;
	fma.rn.f32 	%f121, %f71, %f120, %f119;
	mul.f32 	%f122, %f12, %f9;
	mul.f32 	%f123, %f13, %f9;
	mul.f32 	%f124, %f123, %f97;
	fma.rn.f32 	%f125, %f91, %f122, %f124;
	mul.f32 	%f126, %f14, %f9;
	fma.rn.f32 	%f127, %f103, %f126, %f125;
	neg.f32 	%f128, %f43;
	mul.f32 	%f129, %f111, %f59;
	neg.f32 	%f130, %f129;
	fma.rn.f32 	%f131, %f128, %f110, %f130;
	neg.f32 	%f132, %f68;
	fma.rn.f32 	%f133, %f132, %f114, %f131;
	mul.f32 	%f134, %f105, %f94;
	fma.rn.f32 	%f135, %f81, %f104, %f134;
	fma.rn.f32 	%f136, %f100, %f108, %f135;
	neg.f32 	%f137, %f53;
	mul.f32 	%f138, %f123, %f62;
	neg.f32 	%f139, %f138;
	fma.rn.f32 	%f140, %f137, %f122, %f139;
	neg.f32 	%f141, %f71;
	fma.rn.f32 	%f142, %f141, %f126, %f140;
	mul.f32 	%f143, %f117, %f97;
	fma.rn.f32 	%f144, %f91, %f116, %f143;
	fma.rn.f32 	%f145, %f103, %f120, %f144;
	add.f32 	%f146, %f109, %f115;
	add.f32 	%f147, %f146, %f121;
	add.f32 	%f148, %f147, %f127;
	add.s64 	%rd14, %rd6, %rd9;
	add.f32 	%f149, %f133, %f136;
	add.f32 	%f150, %f149, %f142;
	add.f32 	%f151, %f150, %f145;
	mul.f32 	%f152, %f148, 0fBF000000;
	mul.f32 	%f153, %f151, 0fBF000000;
	st.global.v2.f32 	[%rd14], {%f152, %f153};
	ret;
}

	// .globl	kernelcontract3radmesons
.entry kernelcontract3radmesons(
	.param .u64 .ptr .global .align 16 kernelcontract3radmesons_param_0,
	.param .u64 .ptr .global .align 16 kernelcontract3radmesons_param_1,
	.param .u64 .ptr .global .align 16 kernelcontract3radmesons_param_2,
	.param .u64 .ptr .global .align 16 kernelcontract3radmesons_param_3,
	.param .u64 .ptr .global .align 16 kernelcontract3radmesons_param_4,
	.param .u64 .ptr .global .align 8 kernelcontract3radmesons_param_5
)
{
	.reg .f32 	%f<152>;
	.reg .b32 	%r<7>;
	.reg .b64 	%rd<15>;


	ld.param.u64 	%rd1, [kernelcontract3radmesons_param_0];
	ld.param.u64 	%rd2, [kernelcontract3radmesons_param_1];
	ld.param.u64 	%rd3, [kernelcontract3radmesons_param_2];
	ld.param.u64 	%rd4, [kernelcontract3radmesons_param_3];
	ld.param.u64 	%rd5, [kernelcontract3radmesons_param_4];
	ld.param.u64 	%rd6, [kernelcontract3radmesons_param_5];
	mov.b32	%r1, %envreg3;
	mov.u32 	%r2, %ntid.x;
	mov.u32 	%r3, %ctaid.x;
	mad.lo.s32 	%r4, %r3, %r2, %r1;
	mov.u32 	%r5, %tid.x;
	add.s32 	%r6, %r4, %r5;
	mul.wide.u32 	%rd7, %r6, 64;
	add.s64 	%rd8, %rd2, %rd7;
	ld.global.v4.f32 	{%f1, %f2, %f3, %f4}, [%rd8];
	add.s64 	%rd9, %rd1, %rd7;
	ld.global.v4.f32 	{%f6, %f7, %f8, %f9}, [%rd9];
	ld.global.v4.f32 	{%f12, %f13, %f14, %f15}, [%rd9+16];
	mul.f32 	%f17, %f2, %f12;
	fma.rn.f32 	%f18, %f1, %f6, %f17;
	ld.global.v4.f32 	{%f20, %f21, %f22, %f23}, [%rd9+32];
	fma.rn.f32 	%f25, %f3, %f20, %f18;
	ld.global.v4.f32 	{%f26, %f27, %f28, %f29}, [%rd8+16];
	mul.f32 	%f32, %f27, %f12;
	fma.rn.f32 	%f33, %f26, %f6, %f32;
	fma.rn.f32 	%f35, %f28, %f20, %f33;
	mul.f32 	%f38, %f2, %f13;
	fma.rn.f32 	%f39, %f1, %f7, %f38;
	fma.rn.f32 	%f41, %f3, %f21, %f39;
	mul.f32 	%f42, %f27, %f13;
	fma.rn.f32 	%f43, %f26, %f7, %f42;
	fma.rn.f32 	%f44, %f28, %f21, %f43;
	mul.f32 	%f47, %f2, %f14;
	fma.rn.f32 	%f48, %f1, %f8, %f47;
	fma.rn.f32 	%f50, %f3, %f22, %f48;
	mul.f32 	%f51, %f27, %f14;
	fma.rn.f32 	%f52, %f26, %f8, %f51;
	fma.rn.f32 	%f53, %f28, %f22, %f52;
	add.s64 	%rd10, %rd3, %rd7;
	ld.global.v4.f32 	{%f54, %f55, %f56, %f57}, [%rd10];
	mul.f32 	%f60, %f55, %f12;
	fma.rn.f32 	%f61, %f54, %f6, %f60;
	fma.rn.f32 	%f63, %f56, %f20, %f61;
	ld.global.v4.f32 	{%f64, %f65, %f66, %f67}, [%rd10+16];
	mul.f32 	%f70, %f65, %f12;
	fma.rn.f32 	%f71, %f64, %f6, %f70;
	fma.rn.f32 	%f73, %f66, %f20, %f71;
	mul.f32 	%f74, %f55, %f13;
	fma.rn.f32 	%f75, %f54, %f7, %f74;
	fma.rn.f32 	%f76, %f56, %f21, %f75;
	mul.f32 	%f77, %f65, %f13;
	fma.rn.f32 	%f78, %f64, %f7, %f77;
	fma.rn.f32 	%f79, %f66, %f21, %f78;
	mul.f32 	%f80, %f55, %f14;
	fma.rn.f32 	%f81, %f54, %f8, %f80;
	fma.rn.f32 	%f82, %f56, %f22, %f81;
	mul.f32 	%f83, %f65, %f14;
	fma.rn.f32 	%f84, %f64, %f8, %f83;
	fma.rn.f32 	%f85, %f66, %f22, %f84;
	add.s64 	%rd11, %rd4, %rd7;
	ld.global.v4.f32 	{%f86, %f87, %f88, %f89}, [%rd11];
	mul.f32 	%f92, %f41, %f87;
	fma.rn.f32 	%f93, %f25, %f86, %f92;
	fma.rn.f32 	%f95, %f50, %f88, %f93;
	add.s64 	%rd12, %rd5, %rd7;
	ld.global.v4.f32 	{%f96, %f97, %f98, %f99}, [%rd12];
	mul.f32 	%f102, %f76, %f97;
	fma.rn.f32 	%f103, %f63, %f96, %f102;
	fma.rn.f32 	%f105, %f82, %f98, %f103;
	ld.global.v4.f32 	{%f106, %f107, %f108, %f109}, [%rd11+16];
	mul.f32 	%f112, %f44, %f107;
	fma.rn.f32 	%f113, %f35, %f106, %f112;
	fma.rn.f32 	%f115, %f53, %f108, %f113;
	ld.global.v4.f32 	{%f116, %f117, %f118, %f119}, [%rd12+16];
	mul.f32 	%f122, %f79, %f117;
	fma.rn.f32 	%f123, %f73, %f116, %f122;
	fma.rn.f32 	%f125, %f85, %f118, %f123;
	neg.f32 	%f126, %f25;
	mul.f32 	%f127, %f41, %f97;
	neg.f32 	%f128, %f127;
	fma.rn.f32 	%f129, %f126, %f96, %f128;
	neg.f32 	%f130, %f50;
	fma.rn.f32 	%f131, %f130, %f98, %f129;
	mul.f32 	%f132, %f76, %f87;
	fma.rn.f32 	%f133, %f63, %f86, %f132;
	fma.rn.f32 	%f134, %f82, %f88, %f133;
	neg.f32 	%f135, %f35;
	mul.f32 	%f136, %f44, %f117;
	neg.f32 	%f137, %f136;
	fma.rn.f32 	%f138, %f135, %f116, %f137;
	neg.f32 	%f139, %f53;
	fma.rn.f32 	%f140, %f139, %f118, %f138;
	mul.f32 	%f141, %f79, %f107;
	fma.rn.f32 	%f142, %f73, %f106, %f141;
	fma.rn.f32 	%f143, %f85, %f108, %f142;
	add.f32 	%f144, %f95, %f105;
	add.f32 	%f145, %f144, %f115;
	add.f32 	%f146, %f145, %f125;
	mul.wide.u32 	%rd13, %r6, 8;
	add.s64 	%rd14, %rd6, %rd13;
	add.f32 	%f147, %f131, %f134;
	add.f32 	%f148, %f147, %f140;
	add.f32 	%f149, %f148, %f143;
	mul.f32 	%f150, %f146, 0fBF000000;
	mul.f32 	%f151, %f149, 0fBF000000;
	st.global.v2.f32 	[%rd14], {%f150, %f151};
	ret;
}


  